{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/zhangyong/Documents/data/kaggle/santander_value/train.csv'\n",
    "test_path = '/home/zhangyong/Documents/data/kaggle/santander_value/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods\n",
    "def rmsle(predicted, real):\n",
    "    sum=0.0\n",
    "    for x in range(len(predicted)):\n",
    "        p = np.log(predicted[x]+1)\n",
    "        r = np.log(real[x]+1)\n",
    "        sum = sum + (p - r)**2\n",
    "    return (sum/len(predicted))**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "y = dat['target']\n",
    "X = dat.drop(['ID', 'target'], axis=1).as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1 65574474034602.1250           58.91s\n",
      "         2 63419834268469.6172            1.01m\n",
      "         3 61763317881871.3125           59.16s\n",
      "         4 60190899821405.3750           58.15s\n",
      "         5 58707629844812.4297           57.23s\n",
      "         6 57587889982123.5625           56.29s\n",
      "         7 56459930545619.0547           55.85s\n",
      "         8 55455028938410.2188           55.23s\n",
      "         9 54564502436205.2188           54.59s\n",
      "        10 53731176679960.9062           53.93s\n",
      "        11 52943977067561.0703           53.33s\n",
      "        12 52265723883760.6328           52.65s\n",
      "        13 51643727070793.6016           52.05s\n",
      "        14 51044575966831.0938           51.42s\n",
      "        15 50506435849296.5156           50.74s\n",
      "        16 50015520342951.0859           50.15s\n",
      "        17 49518368815690.1562           49.49s\n",
      "        18 49009974306693.5156           48.91s\n",
      "        19 48349374953105.2891           48.46s\n",
      "        20 47872265644565.0156           47.89s\n",
      "        21 47344582760365.8828           47.35s\n",
      "        22 46875519257529.0234           46.72s\n",
      "        23 46540072621240.6797           46.08s\n",
      "        24 46085792903290.9297           45.49s\n",
      "        25 45683311164359.4531           44.93s\n",
      "        26 45402440473737.6016           44.23s\n",
      "        27 45188667892005.6875           43.51s\n",
      "        28 44851921152783.3125           42.86s\n",
      "        29 44507117290345.5391           42.30s\n",
      "        30 44272887254592.7891           41.65s\n",
      "        31 44029657184610.6250           41.00s\n",
      "        32 43841275329079.2578           40.31s\n",
      "        33 43577684119976.0156           39.71s\n",
      "        34 43297007016195.0000           39.07s\n",
      "        35 43033079503254.8125           38.41s\n",
      "        36 42793127663127.7656           37.79s\n",
      "        37 42608650888614.4922           37.16s\n",
      "        38 42335782558108.6016           36.54s\n",
      "        39 42097075955094.7188           35.94s\n",
      "        40 41941440947422.3984           35.30s\n",
      "        41 41787575253032.9375           34.67s\n",
      "        42 41552747408608.8594           34.08s\n",
      "        43 41380430620127.4453           33.46s\n",
      "        44 41221704792289.1406           32.84s\n",
      "        45 41033880903883.4766           32.23s\n",
      "        46 40894146342309.0547           31.61s\n",
      "        47 40671613983402.5234           31.01s\n",
      "        48 40223703193108.9141           30.49s\n",
      "        49 40027933359269.6016           29.87s\n",
      "        50 39889535066136.0625           29.26s\n",
      "        51 39628407324054.1719           28.68s\n",
      "        52 39500300627102.0391           28.06s\n",
      "        53 39372606430687.5234           27.46s\n",
      "        54 39219861269782.1953           26.85s\n",
      "        55 39030173989704.5312           26.27s\n",
      "        56 38863596767996.7188           25.67s\n",
      "        57 38668120819995.1250           25.09s\n",
      "        58 38504715337673.2891           24.49s\n",
      "        59 38250034144392.9531           23.91s\n",
      "        60 38058811136962.7344           23.33s\n",
      "        61 37948139554078.5469           22.73s\n",
      "        62 37693480928518.7969           22.16s\n",
      "        63 37560762339219.2109           21.58s\n",
      "        64 37448086249285.8672           20.98s\n",
      "        65 37343292574690.5859           20.38s\n",
      "        66 37240299147660.3828           19.78s\n",
      "        67 37126146187621.8359           19.19s\n",
      "        68 37024091358239.3125           18.60s\n",
      "        69 36861545376101.7969           18.01s\n",
      "        70 36625627880791.7109           17.44s\n",
      "        71 36459066704735.1250           16.86s\n",
      "        72 36291850202947.6250           16.27s\n",
      "        73 36114523179527.9375           15.69s\n",
      "        74 35980746978809.3203           15.11s\n",
      "        75 35886493698920.1641           14.51s\n",
      "        76 35791703768069.1250           13.93s\n",
      "        77 35676481346707.5078           13.35s\n",
      "        78 35553375335987.3906           12.76s\n",
      "        79 35429680842791.2656           12.18s\n",
      "        80 35222471013566.4609           11.60s\n",
      "        81 35082357503973.5352           11.02s\n",
      "        82 34990331177830.4219           10.44s\n",
      "        83 34838873169627.0078            9.85s\n",
      "        84 34753797037316.8867            9.27s\n",
      "        85 34669612853800.9922            8.69s\n",
      "        86 34587716069735.3594            8.10s\n",
      "        87 34397590591648.7656            7.53s\n",
      "        88 34287532178789.1914            6.95s\n",
      "        89 34172278044346.6289            6.37s\n",
      "        90 34029825469774.9570            5.79s\n",
      "        91 33918031198347.3398            5.21s\n",
      "        92 33839082177605.3633            4.63s\n",
      "        93 33757233262865.5742            4.05s\n",
      "        94 33677046286850.2617            3.47s\n",
      "        95 33567278353668.7812            2.89s\n",
      "        96 33436877722692.9219            2.31s\n",
      "        97 33260710116569.1250            1.73s\n",
      "        98 33132068010622.3945            1.16s\n",
      "        99 32980362221408.1172            0.58s\n",
      "       100 32827839599453.3047            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 64897296104131.7656           58.90s\n",
      "         2 62710810575224.1328           58.00s\n",
      "         3 60733883681581.0781           57.95s\n",
      "         4 59206687333597.9219           57.30s\n",
      "         5 57685346251942.6562           56.83s\n",
      "         6 56555771123495.5469           56.04s\n",
      "         7 55437740535456.0000           55.27s\n",
      "         8 54398596595648.8438           54.75s\n",
      "         9 53518638023786.2344           54.24s\n",
      "        10 52741809269305.3516           53.56s\n",
      "        11 52065950366828.0547           52.92s\n",
      "        12 51403629270760.9844           52.23s\n",
      "        13 50760897658975.4766           51.68s\n",
      "        14 50268949854198.5078           50.98s\n",
      "        15 49669041923488.2656           50.49s\n",
      "        16 48990845269953.2578           49.99s\n",
      "        17 48570607865991.4844           49.30s\n",
      "        18 48105546485691.2500           48.75s\n",
      "        19 47684689613217.4766           48.20s\n",
      "        20 47287292166586.4219           47.59s\n",
      "        21 46842796322014.2969           47.00s\n",
      "        22 46486668268431.1094           46.37s\n",
      "        23 46171715700386.4219           45.70s\n",
      "        24 45791330934878.4844           45.08s\n",
      "        25 45391117871527.8672           44.49s\n",
      "        26 45148499265040.9609           43.80s\n",
      "        27 44929499681869.8438           43.12s\n",
      "        28 44714276207678.3672           42.44s\n",
      "        29 44518569529095.8594           41.73s\n",
      "        30 44128180571713.0312           41.19s\n",
      "        31 43935670853646.1797           40.51s\n",
      "        32 43732577356906.4297           39.84s\n",
      "        33 43408986247485.8438           39.26s\n",
      "        34 43133475888676.1094           38.64s\n",
      "        35 42890493338829.1875           38.01s\n",
      "        36 42712198120066.2891           37.36s\n",
      "        37 42238126554591.7109           36.89s\n",
      "        38 42065334031068.4688           36.26s\n",
      "        39 41890886122707.6797           35.63s\n",
      "        40 41586217272081.9531           35.03s\n",
      "        41 41420886636189.4453           34.41s\n",
      "        42 41267107507816.9375           33.78s\n",
      "        43 41090795794125.9062           33.16s\n",
      "        44 40936207178901.9219           32.54s\n",
      "        45 40775669261159.7969           31.92s\n",
      "        46 40524615544217.2344           31.34s\n",
      "        47 40191608188713.4297           30.78s\n",
      "        48 39964194941339.7031           30.19s\n",
      "        49 39823712901858.8672           29.57s\n",
      "        50 39682195083939.5625           28.97s\n",
      "        51 39488726247184.9531           28.38s\n",
      "        52 39358965164396.7734           27.77s\n",
      "        53 39226304316416.0312           27.16s\n",
      "        54 39052992790977.0156           26.57s\n",
      "        55 38927196002863.5078           25.97s\n",
      "        56 38713978182666.2266           25.40s\n",
      "        57 38452219794874.1406           24.84s\n",
      "        58 38293544520585.8203           24.26s\n",
      "        59 38171845170919.1094           23.67s\n",
      "        60 38038487777816.5391           23.09s\n",
      "        61 37889587257947.4062           22.50s\n",
      "        62 37718166818566.9219           21.93s\n",
      "        63 37600833405493.4609           21.34s\n",
      "        64 37487135224602.5312           20.76s\n",
      "        65 37375169130032.1250           20.18s\n",
      "        66 37218238523796.4453           19.60s\n",
      "        67 36995461646810.5234           19.04s\n",
      "        68 36877702212940.7578           18.46s\n",
      "        69 36739636867714.8828           17.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        70 36636518489033.9688           17.30s\n",
      "        71 36534534470020.5000           16.71s\n",
      "        72 36260341894275.5391           16.15s\n",
      "        73 36157430589329.8672           15.57s\n",
      "        74 36016616267543.6875           14.99s\n",
      "        75 35918531798678.4766           14.41s\n",
      "        76 35725980250375.3359           13.83s\n",
      "        77 35612933412201.2344           13.25s\n",
      "        78 35408240935367.1719           12.68s\n",
      "        79 35231013474946.3906           12.11s\n",
      "        80 35137720168251.9336           11.52s\n",
      "        81 35044293591178.5469           10.95s\n",
      "        82 34946921621988.8906           10.37s\n",
      "        83 34760985328448.6133            9.79s\n",
      "        84 34639032303998.7930            9.21s\n",
      "        85 34547426055961.6719            8.64s\n",
      "        86 34458091725029.6797            8.06s\n",
      "        87 34364425684871.0391            7.48s\n",
      "        88 34274343763718.3633            6.90s\n",
      "        89 34157083813099.3984            6.33s\n",
      "        90 34074630400599.2383            5.75s\n",
      "        91 33970211929820.8320            5.17s\n",
      "        92 33872648270479.0898            4.59s\n",
      "        93 33727322912663.0664            4.02s\n",
      "        94 33603667914642.8594            3.45s\n",
      "        95 33373929465940.6250            2.87s\n",
      "        96 33201186376574.5273            2.30s\n",
      "        97 33088162483624.4297            1.72s\n",
      "        98 32974868505923.4180            1.15s\n",
      "        99 32900166948459.9375            0.57s\n",
      "       100 32790947744815.8477            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 64920733602246.2422            1.01m\n",
      "         2 62635245046556.9297           59.96s\n",
      "         3 60647120284720.7812           59.07s\n",
      "         4 58913187934342.0312           58.52s\n",
      "         5 57488195670244.5625           57.66s\n",
      "         6 56234843200780.8125           56.93s\n",
      "         7 55106746134127.1562           56.10s\n",
      "         8 54108935758896.7344           55.45s\n",
      "         9 53188874029386.4531           54.78s\n",
      "        10 52392020629700.2109           54.05s\n",
      "        11 51665523580523.4062           53.41s\n",
      "        12 51048334309011.2969           52.74s\n",
      "        13 50442296900147.6406           52.12s\n",
      "        14 49789406116583.1875           51.56s\n",
      "        15 49266775660855.5391           50.95s\n",
      "        16 48805315416906.2500           50.31s\n",
      "        17 48243287980448.9609           49.77s\n",
      "        18 47710615375366.3203           49.28s\n",
      "        19 47305463584408.6094           48.72s\n",
      "        20 46889450407977.9766           48.08s\n",
      "        21 46423618580390.1562           47.64s\n",
      "        22 46011458518122.7344           47.07s\n",
      "        23 45560139104499.8359           46.50s\n",
      "        24 45255132343219.4609           45.82s\n",
      "        25 44961722131912.1719           45.13s\n",
      "        26 44698309643778.7578           44.47s\n",
      "        27 44343636353355.6484           43.86s\n",
      "        28 44093421724207.7031           43.16s\n",
      "        29 43866596080760.1641           42.48s\n",
      "        30 43580284680778.6953           41.83s\n",
      "        31 43393210511707.3125           41.15s\n",
      "        32 43162222900532.7344           40.49s\n",
      "        33 42747219770205.7422           39.96s\n",
      "        34 42567126010504.3672           39.30s\n",
      "        35 42335381574161.7344           38.65s\n",
      "        36 42118756589199.3359           38.12s\n",
      "        37 41959626012851.3125           37.51s\n",
      "        38 41682591376862.8359           36.98s\n",
      "        39 41530224087880.9766           36.33s\n",
      "        40 41381630986873.8203           35.67s\n",
      "        41 41088747283375.0234           35.06s\n",
      "        42 40840339071422.6016           34.46s\n",
      "        43 40580023460330.6875           33.85s\n",
      "        44 40417281818239.4219           33.23s\n",
      "        45 40222193666403.0000           32.61s\n",
      "        46 40067875594247.2812           31.98s\n",
      "        47 39823357755328.4766           31.41s\n",
      "        48 39668546530481.6328           30.83s\n",
      "        49 39515975495949.3984           30.22s\n",
      "        50 39362501187388.8906           29.60s\n",
      "        51 39189820030108.7031           28.99s\n",
      "        52 39068893504217.5781           28.37s\n",
      "        53 38949069904086.2578           27.75s\n",
      "        54 38797608645883.8438           27.14s\n",
      "        55 38636791024313.2656           26.53s\n",
      "        56 38376595174791.6094           25.96s\n",
      "        57 38155638942351.3594           25.37s\n",
      "        58 37988372258648.0469           24.77s\n",
      "        59 37857424227750.9922           24.16s\n",
      "        60 37738745869152.0469           23.56s\n",
      "        61 37586770569170.9297           22.96s\n",
      "        62 37476049656560.3516           22.37s\n",
      "        63 37325762770948.5859           21.78s\n",
      "        64 37224536577590.6562           21.18s\n",
      "        65 37111518331256.6406           20.58s\n",
      "        66 37010039020865.9453           19.98s\n",
      "        67 36788043864327.8438           19.39s\n",
      "        68 36571670808175.5391           18.81s\n",
      "        69 36452506074261.7734           18.22s\n",
      "        70 36349862702423.0625           17.62s\n",
      "        71 36226065371341.3281           17.03s\n",
      "        72 36020850543204.6016           16.45s\n",
      "        73 35912375888387.4688           15.85s\n",
      "        74 35798915369942.5703           15.26s\n",
      "        75 35599150596194.2188           14.68s\n",
      "        76 35512936852804.8750           14.08s\n",
      "        77 35427279107183.7969           13.48s\n",
      "        78 35341700434252.8984           12.89s\n",
      "        79 35257596308053.0234           12.29s\n",
      "        80 35127096669880.2031           11.70s\n",
      "        81 34883139869580.6133           11.12s\n",
      "        82 34794552358407.5508           10.53s\n",
      "        83 34631225101001.4766            9.94s\n",
      "        84 34550748880507.2539            9.35s\n",
      "        85 34404418649776.7148            8.77s\n",
      "        86 34287069397201.8906            8.18s\n",
      "        87 34210828630137.4727            7.59s\n",
      "        88 34106030710093.8320            7.01s\n",
      "        89 34025304673034.6875            6.42s\n",
      "        90 33881695432734.2422            5.83s\n",
      "        91 33808303529144.5781            5.25s\n",
      "        92 33617706676285.2109            4.67s\n",
      "        93 33546889154742.7656            4.08s\n",
      "        94 33459047315467.1133            3.49s\n",
      "        95 33389023059192.7773            2.91s\n",
      "        96 33270114430056.3164            2.33s\n",
      "        97 33160241175415.2930            1.75s\n",
      "        98 33092498170130.6875            1.16s\n",
      "        99 32983653156322.5742            0.58s\n",
      "       100 32844315203666.3398            0.00s\n"
     ]
    }
   ],
   "source": [
    "# model = linear_model.LinearRegression()\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "gb = GradientBoostingRegressor(verbose=2)\n",
    "rmsle_score = make_scorer(rmsle, greater_is_better=False)\n",
    "# clf.fit(X_train, y_train)\n",
    "score = cross_val_score(gb, X, y.as_matrix(), cv = 3, scoring=rmsle_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1 66393678001047.7578            1.32m\n",
      "         2 64132257859307.3828            1.26m\n",
      "         3 62201436714868.0234            1.22m\n",
      "         4 60532155307576.7422            1.21m\n",
      "         5 59138810391467.0469            1.20m\n",
      "         6 57925853343088.3359            1.17m\n",
      "         7 56905275602438.3203            1.16m\n",
      "         8 55925669250711.6016            1.14m\n",
      "         9 55044556158446.1484            1.13m\n",
      "        10 54348271377717.1094            1.11m\n",
      "        11 53622145232138.5312            1.10m\n",
      "        12 52973714701998.0938            1.08m\n",
      "        13 52361815304042.4062            1.07m\n",
      "        14 51772273067051.1484            1.06m\n",
      "        15 51209298150273.0781            1.05m\n",
      "        16 50576492250057.5859            1.04m\n",
      "        17 50124199199719.2656            1.02m\n",
      "        18 49580354762404.6094            1.01m\n",
      "        19 49113544230013.5703            1.00m\n",
      "        20 48592364331513.7422           59.55s\n",
      "        21 48207580831583.8359           58.76s\n",
      "        22 47801906673418.4062           58.01s\n",
      "        23 47491845810180.7891           57.17s\n",
      "        24 47085044610299.4062           56.44s\n",
      "        25 46661035586654.1562           55.70s\n",
      "        26 46361300369564.6875           54.84s\n",
      "        27 46155730489035.4531           53.93s\n",
      "        28 45936552595189.7734           53.03s\n",
      "        29 45746306381977.1562           52.17s\n",
      "        30 45397682354405.6953           51.55s\n",
      "        31 45143791330819.1953           50.76s\n",
      "        32 44824675514481.4141           50.02s\n",
      "        33 44513085698515.5938           49.26s\n",
      "        34 44352342452001.9688           48.41s\n",
      "        35 44195167356245.1406           47.55s\n",
      "        36 43990939820845.3828           46.75s\n",
      "        37 43793516532881.7266           45.94s\n",
      "        38 43588767767423.9141           45.16s\n",
      "        39 43200439844917.8750           44.53s\n",
      "        40 43057765493112.4688           43.72s\n",
      "        41 42884188565030.3984           42.92s\n",
      "        42 42707924964358.0391           42.16s\n",
      "        43 42550739166529.2500           41.38s\n",
      "        44 42381477002065.2812           40.59s\n",
      "        45 42214260720667.2734           39.83s\n",
      "        46 42041945739182.6094           39.05s\n",
      "        47 41862057391399.0859           38.28s\n",
      "        48 41637834437534.4844           37.57s\n",
      "        49 41474009051689.1641           36.81s\n",
      "        50 41293635733096.7266           36.07s\n",
      "        51 41170205153388.6406           35.31s\n",
      "        52 41014971873220.0234           34.58s\n",
      "        53 40861532634191.2344           33.83s\n",
      "        54 40706694474568.0859           33.09s\n",
      "        55 40581387486462.4453           32.34s\n",
      "        56 40413763100080.8750           31.60s\n",
      "        57 40279216148088.9609           30.86s\n",
      "        58 40063399926510.5938           30.15s\n",
      "        59 39942810155005.3672           29.41s\n",
      "        60 39783091977361.7734           28.68s\n",
      "        61 39668513297135.2969           27.94s\n",
      "        62 39536327042852.7656           27.20s\n",
      "        63 39396709870752.0312           26.47s\n",
      "        64 39297025340326.8438           25.73s\n",
      "        65 39148750731890.8281           25.00s\n",
      "        66 39021102242968.6016           24.27s\n",
      "        67 38918783533904.5156           23.54s\n",
      "        68 38789917592772.0234           22.82s\n",
      "        69 38696333966273.7891           22.09s\n",
      "        70 38510040204491.4531           21.39s\n",
      "        71 38407197754158.2344           20.66s\n",
      "        72 38293352660588.3203           19.94s\n",
      "        73 38198823601446.7031           19.22s\n",
      "        74 38110212405328.1719           18.49s\n",
      "        75 37962950185586.3203           17.77s\n",
      "        76 37820975639302.2969           17.06s\n",
      "        77 37683087886263.7031           16.35s\n",
      "        78 37581520414628.3047           15.63s\n",
      "        79 37443968795067.2422           14.92s\n",
      "        80 37338599561270.2812           14.20s\n",
      "        81 37225925874435.8438           13.48s\n",
      "        82 37136462118732.8750           12.76s\n",
      "        83 36998942652668.7031           12.05s\n",
      "        84 36910573224141.8516           11.34s\n",
      "        85 36824170204076.7969           10.63s\n",
      "        86 36708811256770.8594            9.92s\n",
      "        87 36535576710441.7969            9.21s\n",
      "        88 36420151398450.7422            8.49s\n",
      "        89 36297566639070.5391            7.78s\n",
      "        90 36222763751474.4844            7.07s\n",
      "        91 36148150265747.3359            6.36s\n",
      "        92 36056463733895.8750            5.65s\n",
      "        93 35971942116097.8047            4.94s\n",
      "        94 35847156295174.3828            4.24s\n",
      "        95 35770594233015.0938            3.53s\n",
      "        96 35698451446792.1797            2.82s\n",
      "        97 35571646433104.0781            2.12s\n",
      "        98 35435917945212.6484            1.41s\n",
      "        99 35334306361727.7578            0.71s\n",
      "       100 35195899390849.0938            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(test, columns=['ID'])\n",
    "out['target'] = gb.predict(test.drop(['ID'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.872786068276973"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(predict, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('/home/zhangyong/Downloads/toasts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
